# 锁

## 概念

锁机制用于管理对共享资源的并发访问。数据库系统使用锁是为了支持对共享资源进行并发访问，提供数据的完整性和一致性。

InnoDB存储引擎会在行级别上对**表数据**上锁，也会在**数据库内部**其他多个地方使用锁，从而允许对多种不同资源提供并发访问。例如，操作缓冲池中的LRU列表，删除、添加、移动LRU列表中的元素，为了保证一致性，必须有锁的介入。

## lock 与 latch

在数据库中，lock与latch都可以被称为“锁”。

**latch**一般称为闩锁（轻量级的锁），因为其要求锁定的时间必须非常短。若持续的时间长，则应用的性能会非常差。在InnoDB存储引擎中，latch又可以分为`mutex`（互斥量）和`rwlock`（读写锁）。latch的对象是*线程*，其目的是用来保证并发线程操作*内存*中临界资源的正确性，并且通常*没有死锁检测的机制*。

**lock**的对象是*事务*，用来锁定的是*数据库中的对象*，如表、页、行。并且一般lock的对象仅在事务`commit`或`rollback`后进行释放（不同事务隔离级别释放的时间可能不同）。此外，`lock`同大多数数据库中一样，是*有死锁机制*的。

![lock与latch的比较](imgs/lock%E4%B8%8Elatch%E7%9A%84%E6%AF%94%E8%BE%83.png)

对于InnoDB存储引擎中的latch，可以通过命令`SHOW ENGINE INNODB MUTEX`来进行查看。

## InnoDB存储引擎中的锁

### 锁的类型

#### 行级锁

InnoDB存储引擎实现了如下两种标准的**行级锁**：

- **共享锁（S Lock）**，允许事务读一行数据。
- **排他锁（X Lock）**，允许事务删除或更新一行数据。

![共享锁和排他锁的兼容性](imgs/%E5%85%B1%E4%BA%AB%E9%94%81%E5%92%8C%E6%8E%92%E4%BB%96%E9%94%81%E7%9A%84%E5%85%BC%E5%AE%B9%E6%80%A7.png)

可以发现X锁与任何的锁都不兼容，而S锁仅和S锁兼容。需要特别注意的是，S和X锁都是行锁，兼容是指对同一记录（row）锁的兼容性情况。

#### 意向锁

InnoDB存储引擎支持**多粒度（granular）锁定**，这种锁定允许事务在行级上的锁和表级上的锁同时存在。为了支持在不同粒度上进行加锁操作，InnoDB存储引擎支持一种额外的锁方式，称之为**意向锁（Intention Lock）**。意向锁是将锁定的对象分为多个层次，意向锁意味着事务希望在更细粒度（fine granularity）上进行加锁。

若将上锁的对象看成一棵树，那么对最下层的对象上锁，也就是对最细粒度的对象进行上锁，那么首先需要对粗粒度的对象上锁。例如下图，如果需要对页上的**记录r**进行上X锁，那么分别需要对*数据库A*、*表*、*页*上意向锁IX，最后对**记录r**上X锁。若其中任何一个部分导致等待，那么该操作需要等待粗粒度锁的完成。

![层次结构](imgs/%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84.png)

InnoDB存储引擎支持意向锁设计比较简练，其意向锁即为**表级别**的锁，而并没有页级别的意向锁。设计目的主要是为了在一个事务中揭示下一行将被请求的锁类型。其支持两种意向锁：

- **意向共享锁（IS Lock）**，事务想要获得一张表中某几行的共享锁
- **意向排他锁（IX Lock）**，事务想要获得一张表中某几行的排他锁

由于InnoDB存储引擎支持的是行级别的锁，因此意向锁其实不会阻塞除全表扫以外的任何请求。故表级意向锁与行级锁的兼容性如下表所示。

![InnoDB存储引擎中锁的兼容性](imgs/InnoDB%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E%E4%B8%AD%E9%94%81%E7%9A%84%E5%85%BC%E5%AE%B9%E6%80%A7.png)

##### 意向锁演示

简单创建一个表`test`,插入一些简单的数据。

```sql
CREATE TABLE `test` (
  `id` int NOT NULL AUTO_INCREMENT,
  `num` int NOT NULL,
  `str` varchar(128) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;

INSERT INTO `test` (`num`, `str`) VALUES ('1', 'foo'), ('1', 'bar'), ('2', 'foobar'), ('3', 'hello world');
```

如果我们直接对`test`表记录进行如下修改，实际上会在在`test`表上添加一个IX意向锁，因为现在`test`表上没有其他锁，所以兼容；之后再在id等于4的列上添加X锁，同样锁兼容，因此修改成功。

```sql
UPDATE `test` SET `num` = '4' WHERE (`id` = '4');
```

但是如果在修改之前先为`test`表添加一个S锁，之后在进行修改。

```sql
-- 为test表添加S锁
LOCK TABLE test READ;
-- 无法修改
UPDATE `test` SET `num` = '4' WHERE (`id` = '4');
```

执行上述SQL会发现无法对记录进行修改，因为在对id为4的记录添加X所之前，会先对`test`表添加IX意向锁。但是在`test`表添加意向锁之前，`test`表上有S锁，因为S锁与IX意向锁不锁兼容，所以无法修改，要等到`test`表S锁解锁后才能够修改。

```sql
-- 表解锁
UNLOCK tables;
-- 修改成功
UPDATE `test` SET `num` = '4' WHERE (`id` = '4');
```
####  插入意向锁

`INSERT` 语句在执行插入之前，会先在 gap 中加入**插入意向锁**。如果是唯一索引，还会进行 Duplicate Key 判断，如果存在相同 Key 且该 Key 被加了互斥锁，则还会加共享锁，然后等待（因为这个相同的 Key 之后有可能会回滚删除，这里非常容易死锁）。等到成功插入后，会在这条记录上加**排他(X)记录锁**。

插入意向锁详细参考：

1. [论 MySql InnoDB 如何通过插入意向锁控制并发插入](https://juejin.cn/post/6844903666856493064)
2. [故障分析 | MySQL Insert 加锁与死锁分析](https://opensource.actionsky.com/20190331-mysql-insert/)
3. [MySQL InnoDB中的锁-插入意向锁（Insert Intention Lock）](https://developer.aliyun.com/article/873307)
### 锁的信息

> 注：要求MySQL版本大于8.0

`SHOW ENGINE INNODB STATUS`命令来查看当前锁请求的信息：

```text
...
------------
TRANSACTIONS
------------
Trx id counter 23026
Purge done for trx's n:o < 23024 undo n:o < 0 state: running but idle
History list length 0
LIST OF TRANSACTIONS FOR EACH SESSION:
---TRANSACTION 421962756665288, not started
0 lock struct(s), heap size 1128, 0 row lock(s)
---TRANSACTION 421962756664480, not started
0 lock struct(s), heap size 1128, 0 row lock(s)
---TRANSACTION 421962756663672, not started
0 lock struct(s), heap size 1128, 0 row lock(s)
---TRANSACTION 421962756662056, not started
0 lock struct(s), heap size 1128, 0 row lock(s)
---TRANSACTION 421962756661248, not started
0 lock struct(s), heap size 1128, 0 row lock(s)
---TRANSACTION 421962756660440, not started
0 lock struct(s), heap size 1128, 0 row lock(s)
---TRANSACTION 421962756659632, not started
0 lock struct(s), heap size 1128, 0 row lock(s)
---TRANSACTION 421962756658824, not started
0 lock struct(s), heap size 1128, 0 row lock(s)
...
```

**事务信息**被存储在`information_schema`架构下的`INNODB_TRX`表中。`INNODB_TRX`表由8个字段组成。

![表INNODB_TRX的结构说明](imgs/%E8%A1%A8INNODB_TRX%E7%9A%84%E7%BB%93%E6%9E%84%E8%AF%B4%E6%98%8E.png)

InnoDB的**锁信息**被存储在`performance_schema`架构下的`data_locks`表中，该表有如下字段组成。

![data_locks的结构](imgs/data_locks%E7%9A%84%E7%BB%93%E6%9E%84.png)

在通过表`data_locks`查看了每张表上锁的情况后，用户就可以来判断由此引发的等待情况了。当事务较小时，用户就可以人为地、直观地进行判断了。但是当事务量非常大，其中锁和等待也时常发生，这个时候就不这么容易判断。但是通过`performance_schema`架构下的`data_lock_waits`表，可以很直观地反映当前事务的等待。表`data_lock_waits`由4个字段组成。

![data_lock_waits的结构](imgs/data_lock_waits%E7%9A%84%E7%BB%93%E6%9E%84.png)

### 一致性非锁定读（快照读）

**一致性的非锁定读（consistent nonlocking read）**是指InnoDB存储引擎通过行**多版本控制（multi versioning）**的方式来读取当前执行时间数据库中行的数据。

**MVCC多版本控制**指的是一种提高并发的技术。最早的数据库系统，只有*读读*之间可以并发，*读写*，*写读*，*写写*都要阻塞。引入多版本之后，只有*写写*之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。

InnoDB的一致性的非锁定读就是通过MVCC实现的，MySQL的大多数事务型存储引擎实现的都不是简单的行级锁。基于提升并发性能的考虑，它们一般都同时实现了多版本并发控制（MVCC）。MVCC的实现，是通过保存数据在某一个时间点的快照来实现的。因此每一个事务无论执行多长时间看到的数据，都是一样的。

MVCC的核心实现主要基于两部分：**多事务并发操作数据**与**一致性读实现**。

#### 多事务并发操作数据

多事务并发操作数据核心基于Undo log进行实现，Undo log可以用来做事务的回滚操作，保证事务的原子性。同时可以用来构建数据修改之前的版本，支持多版本读。

InnoDB中，每一行记录都有两个隐藏列：`DATA_TRX_ID`和`DATA_ROLL_PTR`。(若没有主键，则还有一个`DB_ROW_ID`隐藏主键)

- `DATA_TRX_ID`：记录最近更新这条记录的事务ID(6字节)
- `DATA_ROLL_PTR`：回滚指针，指向Undo Log记录。每次对某条记录进行改动时，该列会存一个指针，可以通过这个指针找到该记录修改前的信息。(7字节)
- `DB_ROW_ID`：行标识（隐藏单增ID），没有主键时主动生成(6字节)

当存在多个事务进行并发操作数据时，不同事务对同一行的更新操作产生多个版本，通过回滚指针`DATA_ROLL_PTR`将这些版本链接成一条**Undo Log链**。

> Undo Log分为`INSERT`和`UPDATE`两种。`DELETE`可以看做是一种特殊的`UPDATE`，即在记录上修改删除标记。
>
> - `INSERT`：当进行插入数据操作时，会生成`Insert Undo Log`，只在事务回滚时需要, 并且在事务提交后就可以立即丢弃。
> - `UPDATE/DELETE`：事务对记录进行`Delete`和`Update`操作时产生`Undo Log`，并将当前数据记录中的`DB_ROLL_PTR`字段指向它，它不仅在事务回滚时需要，一致性读也需要，所以不能随便删除，只有当数据库所使用的快照中不涉及该日志记录，对应的回滚日志才会被*Purge线程*删除。

![版本链](imgs/%E7%89%88%E6%9C%AC%E9%93%BE.drawio.png)

更新/删除操作过程：

1. 将待操作的行加排他锁。
2. 将该行原本的值拷贝到Undo Log中，`DB_TRX_ID`和`DB_ROLL_PTR`保持不变。（形成历史版本）
3. 修改该行的值，更新该行的`DATA_TRX_ID`为当前操作事务的事务ID，将`DATA_ROLL_PTR`指向第二步拷贝到Undo Log链中的旧版本记录。（通过`DB_ROLL_PTR`可以找到历史记录）
4. 记录Redo Log，包括Undo Log中的修改。

插入操作过程：

1. 产生Insert Undo Log
2. 产生新的记录，其`DATA_TRX_ID`为当前插入记录的事务ID，`DATA_ROLL_PTR`为`NULL`。
3. 记录Redo Log，包括Undo Log中的修改。

#### 一致性读实现

在InnoDB中，对于不同的事务隔离级别，一致性读实现均不相同，具体如下：

- `READ UNCOMMITED`隔离级别：直接读取版本的最新记录。
- `SERIALIZABLE`隔离级别：通过加锁互斥访问数据实现。
- `READ COMMITED`和`REPEATABLE READ`隔离级别：使用版本链实现。(ReadView，可读性视图)

**ReadView**是事务开启时，当前所有活跃事务（还未提交的事务）ID的集合，ReadView数据结构决定了不同事务隔离级别下，数据的可见性。

ReadView的数据结构如下图所示：

![ReadView数据结构](imgs/ReadView.drawio.png)

ReadView的组成：

- `up_limit_id`：最先开始的事务，该SQL启动时，当前事务链表中最小的事务ID编号，也就是当前系统中创建最早但还未提交的事务——**低水位线**。
  - 如果读取出来的数据行上的的`DB_TRX_ID`小于`up_limit_id`，则说明这条记录的最后修改在ReadView创建之前，因此这条记录可以被看见。
- `low_limit_id`：最后开始的事务，该SQL启动时，当前事务链表中最大的事务ID编号，也就是最近创建的除自身以外最大事务编号——**高水位线**；
  - 如果读取出来的数据行上的的`DB_TRX_ID`大于`low_limit_id`，则说明这条记录的最后修改在ReadView创建之后，因此这条记录肯定不可以被看见。
- `m_ids`：当前活跃事务ID列表，所有事务链表中事务的ID集合
  - 如果读取出来的数据行上的的`DB_TRX_ID`在`up_limit_id`和`low_limit_id`之间，则查找该数据上的`DB_TRX_ID`是否在ReadView的`m_ids`列表中：
    - 如果存在，则表示这条记录的最后修改是在ReadView创建之时，被另外一个活跃事务所修改，所以这条记录也不可以被看见。
    - 如果不存在，则表示这条记录的最后修改在ReadView创建之前，所以可以看到。

> 注：事务ID越小，事务开始的越早；事务ID越大，事务开始的越晚。

##### REPEATABLE READ下的ReadView

每个事务首次执行`SELECT`语句时，会将当前系统所有活跃事务拷贝到一个列表中生成ReadView。每个事务后续的`SELECT`操作复用其之前生成的ReadView。`UPDATE`,`DELETE`,`INSERT`对一致性读快照无影响。

示例：事务A，B同时操作同一行数据

- 若事务A的第一个`SELECT`在事务B提交之前进行，则即使事务B修改记录后先于事务A进行提交，事务A后续的`SELECT`操作也无法读到事务B修改后的数据。
- 若事务A的第一个`SELECT`在事务B修改数据并提交事务之后，则事务A能读到事务B的修改。

针对RR隔离级别，在第一次创建ReadView后，这个ReadView就会一直持续到事务结束，也就是说在事务执行过程中，数据的可见性不会变，所以在事务内部不会出现不一致的情况。

##### READ COMMITED下的ReadView

每次SELECT执行，都会重新将当前系统中的所有活跃事务拷贝到一个列表中生成ReadView。

针对RC隔离级别，事务中的每个查询语句都单独构建一个ReadView，所以如果两个查询之间有事务提交了，两个查询读出来的结果就不一样。

### 一致性锁定读(当前读)

在默认配置下，即事务的隔离级别为`REPEATABLE READ`模式下，InnoDB存储引擎的`SELECT`操作使用一致性非锁定读，实际上读取的是MVCC中的快照。但是在某些情况下，用户需要显式地对数据库读取操作进行加锁以保证数据逻辑的一致性，同时读取数据库中真实的数据。而这要求数据库支持加锁语句，即使是对于`SELECT`的只读操作。InnoDB存储引擎对于`SELECT`语句支持两种**一致性的锁定读（locking read）**操作：

- `SELECT…FOR UPDATE`
- `SELECT…LOCK IN SHARE MODE`

`SELECT…FOR UPDATE`对读取的行记录加一个**X锁**，其他事务不能对已锁定的行加上任何锁。`SELECT…LOCK IN SHARE MODE`对读取的行记录加一个S锁，其他事务可以向被锁定的行加**S锁**，但是如果加X锁，则会被阻塞。

对于一致性非锁定读(快照读)，即使读取的行已被执行了`SELECT…FOR UPDATE`，也是可以进行读取的。

### 自增长与锁

参考:[深入剖析 MySQL 自增锁](https://juejin.cn/post/6968420054287253540)

在InnoDB存储引擎的内存结构中，对每个含有自增长值的表都有一个**自增长计数器（auto-increment counter）**。当对含有自增长的计数器的表进行插入操作时，这个计数器会被初始化，执行如下的语句来得到计数器的值：

```sql
SELECT AUTO_INCREMENT FROM information_schema.TABLES where TABLE_SCHEMA = 'database' and TABLE_NAME = 'table';
```

插入操作会将自增长的计数器值赋值给增长列之后进行再进行自增操作。这个实现方式称做**自增锁（`AUTO-INC Locking`）**。这种锁其实是采用一种特殊的**表锁机制**，为了提高插入的性能，锁不是在一个事务完成后才释放，而是*在完成对自增长值插入的SQL语句后立即释放*。

虽然`AUTO-INC Locking`从一定程度上提高了并发插入的效率，但还是存在一些性能上的问题。首先，对于有自增长值的列的并发插入性能较差，事务必须等待前一个插入的完成（虽然不用等待事务的完成）。其次，对于`INSERT…SELECT`的大数据量的插入会影响插入的性能，因为另一个事务中的插入会被阻塞。

从MySQL 5.1.22版本开始，InnoDB存储引擎中提供了一种**轻量级互斥量的自增长实现机制**，这种机制大大提高了自增长值插入的性能。并且从该版本开始，InnoDB存储引擎提供了一个参数`innodb_autoinc_lock_mode`来控制自增长的模式，该参数的默认值为`1`。

在继续讨论新的自增长实现方式之前，需要对自增长的插入进行分类，如下表所示。

![插入类型](imgs/%E6%8F%92%E5%85%A5%E7%B1%BB%E5%9E%8B.png)

接着来分析参数`innodb_autoinc_lock_mode`以及各个设置下对自增的影响，其总共有三个有效值可供设定，即传统模式`0`、连续模式`1`、交叉模式`2`。

#### 传统模式

传统模式（Traditional），说白了就是还没有锁模式这个概念时，InnoDB 的**自增锁**运行的模式。只是后面版本更新，InnoDB 引入了锁模式的概念，然后 InnoDB 给了这种以前默认的模式一个名字，叫传统模式。

当用户向包含了`AUTO_INCREMENT`列的表中插入数据时，都会持有这么一个特殊的表锁——**自增锁（AUTO-INC）**，并且当语句执行完之后就会释放。这样一来可以保证单个语句内生成的自增值是连续的。

这样一来，传统模式的弊端就自然暴露出来了，如果有多个事务并发的执行`INSERT`操作，`AUTO-INC Locking`的存在会使得 MySQL 的性能略有下降，因为同时只能执行一条`INSERT`语句。

#### 连续模式

连续模式（Consecutive）是 MySQL 8.0 之前默认的模式，之所以提出这种模式，是因为传统模式存在影响性能的弊端，所以才有了连续模式。

在锁模式处于连续模式下时，对于像是`simple inserts`这样能在插入前就确定插入行数的语句，就不会使用自增锁，而会使用互斥量（mutex）将需要分配的空间预留出来，之后就可以继续执行下一个语句了。而对于像是`bulk inserts`这样不能提前确认数据量的语句，则还是会去获取自增锁。

在这种配置下，如果不考虑回滚操作，对于自增值列的增长还是连续的。

#### 交叉模式

交叉模式（Interleaved）下，对于所有`INSERT-like`语句自增长值的产生都不会使用 AUTO-INC Locking自增锁，而是使用较为轻量的 mutex 锁。这样一来，多条 `INSERT` 语句可以并发的执行，这也是三种锁模式中扩展性最好的一种。

并发执行所带来的副作用就是单个`INSERT`的自增值并不连续，因为`AUTO_INCREMENT`的值分配会在多个`INSERT`语句中来回交叉的执行。

#### 自增与主从同步

先了解一下MySQL的Binlog。Binlog一般用于MySQL的数据复制，通俗一点就是用于主从同步。在MySQL中Binlog的格式有3种，分别是：

- `Statement`：基于语句，只记录对数据做了修改的SQL语句，能够有效的减少Binlog的数据量，提高读取、基于Binlog重放的性能
- `Row`：只记录被修改的行，所以Row记录的Binlog日志量一般来说会比Statement格式要多。基于Row的Binlog日志非常完整、清晰，记录了所有数据的变动，但是缺点是可能会非常多，例如一条`update`语句，有可能是所有的数据都有修改；再例如`alter table`之类的，修改了某个字段，同样的每条记录都有改动。
- `Mixed`：Statement和Row的结合，怎么个结合法呢。例如像`alter table`之类的对表结构的修改，采用Statement格式。其余的对数据的修改例如`update`和`delete`采用Row格式进行记录。

如果 MySQL 采用的格式为**Statement**，那么MySQL的主从同步实际上同步的就是一条一条的SQL语句。

- **连续模式**能保证主从同步能正常进行，但是效率不及交叉模式；
- **交叉模式**并发情况下`INSERT`语句的执行顺序就无法得到保障。因此交叉模式下，`INSERT`同时交叉执行，并且`AUTO_INCREMENT`交叉分配将会直接导致主从之间同行的数据主键ID不同。而这对主从同步来说是灾难性的。

总结：

- 有主从同步
  - Binlog: Statement
        **连续模式**
  - Binlog：Row
        **交叉模式**
- 无主从同步
    **交叉模式**

#### 外键和锁

外键主要用于引用完整性的约束检查。

在InnoDB存储引擎中，对于一个外键列，如果没有显式地对这个列加索引，InnoDB存储引擎自动对其加一个索引，因为这样可以避免表锁。

对于**外键值的插入或更新**，首先需要查询父表中的记录，即`SELECT`父表。但是对于**父表的`SELECT`操作**，不是使用一致性非锁定读的方式，因为这样会发生数据不一致的问题，因此这时使用的是**一致性锁定读`SELECT…LOCK IN SHARE MODE`方式**，即主动对父表加一个S锁。如果这时父表上已经这样加X锁，子表上的操作会被阻塞，如下表所示。

![外键测试用例](imgs/%E5%A4%96%E9%94%AE%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B.png)

在上述的例子中，两个会话中的事务都没有进行`COMMIT`或`ROLLBACK`操作，而会话B的操作会被阻塞。这是因为`id`为`3`的父表在会话A中已经加了一个X锁，而此时在会话B中用户又需要对父表中id为3的行加一个S锁，这时INSERT的操作会被阻塞。设想如果访问父表时，使用的是一致性的非锁定读，这时Session B会读到父表有`id=3`的记录，可以进行插入操作。但是如果会话A对事务提交了，则父表中就不存在`id`为`3`的记录。数据在父、子表就会存在不一致的情况。

## 锁的算法

参考：

1. [MySQL InnoDB锁类型](https://www.jianshu.com/p/6e815c767602)
2. [InnoDB Locking](https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html)

InnoDB存储引擎有3种行锁的算法，其分别是：

- `Record Lock`：**记录锁**是单个行记录上的锁
  - `LOCK_MODE`: `S,REC_NOT_GAP` / `X,REC_NOT_GAP`
- `Gap Lock`：**间隙锁**，锁定一个范围，但不包含记录本身。RR特有
  - `REPEATABLE-READ`隔离级别特有
  - `LOCK_MODE`: `S,GAP` / `X,GAP`
- `Next-Key Lock`：**临键锁**是索引记录上的记录锁和索引记录之前的间隙上的间隙锁的组合（Gap Lock + Record Lock）。
  - 应为间隙锁是`REPEATABLE-READ`隔离级别特有，所以临键锁也是
  - InnoDB存储引擎在索引上的当前读（`SELECT ... FOR UPDATE` / `SELECT ... LOCK IN SHARE MODE`）都是使用临键锁来进行锁定的，其设计目的是为了解决当前读的幻读问题。
  - 唯一索引的临键锁会被优化为记录锁
  - 如果索引值命中多个，则都加上临键锁。例如`i`值为`8`, `10`, `10`, `11`, `18`，当使用`where i=10 for update`条件时，两个`i=10`的临键锁区间为`(8,10]`和`(10,10]`。
  - `LOCK_MODE`: `S` / `X`

### 锁的算法演示

新建表`z`，表`z`中存在一个主键索引和一个二级索引`idx_b`和然后随便创建数据放入表中。

```sql
-- 创建表
CREATE TABLE z (
    a INT,
    b INT,
    PRIMARY KEY (a),
    KEY idx_b (b)
);

-- 插入数据
INSERT INTO z VALUES (1, 101), (2, 102), (3, 103),(4, 103), (5, 104), (6, 105);
```

开启事务后，使用当前读（X锁）通过辅助索引`idx_b`进行查询。

```sql
begin;
SELECT * FROM z where b = 103 FOR UPDATE;
```

访问`performance_schema`数据库下的`data_locks`表查看表信息。

```sql
SELECT OBJECT_SCHEMA, OBJECT_NAME, INDEX_NAME, LOCK_TYPE, LOCK_MODE, LOCK_DATA FROM performance_schema.data_locks;
```

查询结果如下表所示，第一行的表意向锁IX暂不考虑，接下来的两行数据分别表示临键锁对应的区间分别为 (102 ,103] 和 (103, 103]，需要注意的是因为在`idx_b`索引上有两个103，所以创建两个**临键锁**。InnoDB存储引擎还会对辅助索引的下一个键值区间(103, 104)加上一个**区间锁**，用于防止该区间内的幻读问题。除此之外在主键索引上还需要将103对应的主键索引上的记录id分别对应3和4的记录加两个**记录锁**，防止其他事务对其进行修改操作。

```text
# OBJECT_SCHEMA OBJECT_NAME INDEX_NAME LOCK_TYPE LOCK_MODE LOCK_DATA
employees z  TABLE IX 
employees z idx_b RECORD X 103, 3
employees z idx_b RECORD X 103, 4
employees z PRIMARY RECORD X,REC_NOT_GAP 3
employees z PRIMARY RECORD X,REC_NOT_GAP 4
employees z idx_b RECORD X,GAP 104, 5
```

### 唯一索引锁降级

> 当查询的索引含有唯一属性（唯一索引）时，InnoDB存储引擎会对临键锁进行优化，将其降级为记录锁，即锁住索引本身，而不是范围。
> ——《MySQL技术内幕 InooDB存储引擎》

那么问题来了，为什么唯一索引的临键锁可以降级为记录所呢？

要解答这个问题，首先要搞清楚引入临键锁的意义。引入临键锁的目的是为避免幻读问题。所谓幻读就是一个事务中两个相同读取操作中，第二次读取比第一次读取多出了其他事务插入的数据。为了解决这个问题在第一次读取的时候，数据库应该做到将插入能够导致幻读的索引区间加锁，来预防幻读的发生。

以上表`z`为例，在插入完数据之后的索引idx_b索引记录如下图。

![idx_b索引记录](imgs/idx_b%E7%B4%A2%E5%BC%95%E8%AE%B0%E5%BD%95.drawio.png)

当用户事务A开启事务执行如下查询时，会查询到`idx_b`索引中索引键为103的主键，~再根据主键进行回表查询获取记录信息~通过覆盖索引获取查询信息即可。如果其他事务插入数据，那么只有插入 `b = 103` 条件的记录才能导致幻读，而 `b = 103` 的记录可能插入的位置为 idx_b 索引中`(102, 104)` 区间中，所以只要把这个区间上加锁就可以避免幻读的发生。

```sql
-- 事务A
BEGIN;
SELECT * FROM z WHERE b = 103 FOR UPDATE;
```

访问`performance_schema`数据库下的`data_locks`表查看锁信息，看看InnoDB时怎么做的。可见InnoDB会为`idx_b`索引添加`(102, 103]`区间的临键锁、`(103, 103]`区间的临键锁和`(103, 104)`区间的间隙锁来防止其他事务的插入进而造成幻读像现象。得到如下结果：

![idx_b加锁情况](imgs/idx_b%E5%8A%A0%E9%94%81%E6%83%85%E5%86%B5.drawio.png)

如果此时事务B插入了一条数据，这条数据可能会被插入至`(102, 103)`、`(103, 103)`或者`(103, 104)`区间，但是这些区间上都被加上了X锁，无法插入，需要等待事务A释放锁之后才能进行插入。

```sql
-- 事务B
BEGIN;
INSERT INTO z VALUES (7, 103);
```

但是对于唯一索引，我们新建一张新表`y`，表主键`a`，唯一键`b`。随便构造些数据插入表中。

```sql
CREATE TABLE y (
    a INT,
    b INT,
    PRIMARY KEY (a),
    KEY uniq_key (b)
);

INSERT INTO y VALUES (1, 101), (2, 103), (3, 105), (4, 107), (5, 109);
```

如果此时开启一个事务，执行执行当前读（X锁）查询`b = 105`条件的数据。

```sql
BEGIN;
SELECT * FROM y WHERE b = 105 FOR UPDATE;
```

访问`performance_schema`数据库下的`data_locks`表查看锁信息，发现InnoDB只为`unique_key`索引添加了记录锁，而并不是像非唯一索引一样，将原本的(103, 105]临键锁和(105，107)间隙锁降级为105的记录锁。究其原因就是因为唯一索引只会将不会重复插入`b = 105`的记录，因为存在唯一性约束，所以只添加了记录锁防止索引记录并发修改。

提交上述事务之后，开启一个新的事务执行如下查询：

```sql
BEGIN;
SELECT * FROM y WHERE b BETWEEN 103 and 107 FOR UPDATE;
```

想一想，如果要避免幻读的发生，只需要避免满足`b BETWEEN 103 and 107`条件的记录的插入，所以需要对[103, 107]区间加锁。对于边界值`b = 103`或`b = 107`的插入，因为是b是唯一索引，为了满足唯一性约束，并不会插入至103记录之前和107记录之后，所以并不需要锁103之前和107之后的区间。但是InnoDB仍然在区间添加锁（个人认为可以进行优化）。

### 区间锁显示关闭

因为区间锁是RR隔离级别特有的锁，可以将隔离级别设置为`READ COMMITTED`来显示关闭间隙锁。关闭之后，同样执行如下查询。

```sql
begin;
SELECT * FROM z where b = 103 FOR UPDATE;
SELECT OBJECT_SCHEMA, OBJECT_NAME, INDEX_NAME, LOCK_TYPE, LOCK_MODE, LOCK_DATA FROM performance_schema.data_locks;
```

可以发现`LOCK_TYPE`为`RECORD`的锁都是`X,REC_NOT_GAP`，即记录锁。并没有出现间隙锁或者临键锁。

```text
# OBJECT_SCHEMA OBJECT_NAME INDEX_NAME LOCK_TYPE LOCK_MODE LOCK_DATA
employees z  TABLE IX 
employees z idx_b RECORD X,REC_NOT_GAP 103, 3
employees z idx_b RECORD X,REC_NOT_GAP 103, 4
employees z PRIMARY RECORD X,REC_NOT_GAP 3
employees z PRIMARY RECORD X,REC_NOT_GAP 4
```

## 锁问题

### 脏读

**脏读**指的就是在不同的事务下，当前事务可以读到另外事务未提交的数据，简单来说就是可以读到**脏数据**。

需要注意的是，**脏数据**和之前所介绍的**脏页**完全是两种不同的概念。

- **脏页**指的是在缓冲池中已经被修改的页，但是还没有刷新到磁盘中，即数据库实例内存中的页和磁盘中的页的数据是不一致的，当然在刷新到磁盘之前，日志都已经被写入到了重做日志文件中。
  - 对于脏页的读取，是非常正常的。脏页是因为数据库实例内存和磁盘的异步造成的，这并不影响数据的一致性（或者说两者最终会达到一致性，即当脏页都刷回到磁盘）。并且因为脏页的刷新是异步的，不影响数据库的可用性，因此可以带来性能的提高。
- **脏数据**是指事务对缓冲池中行记录的修改，并且还没有被提交（commit）。
  - 脏数据却截然不同，脏数据是指未提交的数据，如果读到了脏数据，即一个事务可以读到另外一个事务中未提交的数据，则显然违反了数据库的隔离性。

### 不可重复读

不可重复读是指在一个事务内多次读取同一数据集合。在这个事务还没有结束时，另外一个事务也访问该同一数据集合，并做了一些DML操作。因此，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的情况，这种情况称为**不可重复读**。

不可重复读和脏读的区别是：脏读是读到未提交的数据，而不可重复读读到的却是已经提交的数据，但是其违反了数据库事务一致性的要求。

在InnoDB中的**读已提交隔离级别**使用MVCC来解决不可重复读问题。

### 幻读

参考:[Innodb中的事务隔离级别和锁的关系](https://tech.meituan.com/2014/08/20/innodb-lock.html)

**幻读**是指在同一事务下，连续执行两次同样的SQL语句可能导致不同的结果，第二次的SQL语句可能会返回之前不存在的行。

很多人容易搞混不可重复读和幻读，确实这两者有些相似。但不可重复读重点在于`update`和`delete`，而幻读的重点在于`insert`。

在InnoDB的可重复读隔离级别用于解决幻读问题。对于快照读的幻读问题可以同样是使用MVCC来解决；而对于当前读的幻读问题，InnoDB使用Next-Key Lock来解决。

而InnoDB的**读已提交隔离级别**和**可重复读隔离级别**的非一致性锁定读的区别时ReadView的实现不同。

### 丢失更新

**丢失更新**是另一个锁导致的问题，简单来说其就是一个事务的更新操作会被另一个事务的更新操作所覆盖，从而导致数据的不一致。

例如：

1. 事务T1将行记录`r`更新为`v1`，但是事务T1并未提交。
2. 与此同时，事务T2将行记录`r`更新为`v2`，事务T2未提交。
3. 事务T1提交。
4. 事务T2提交。

但是，在当前数据库的任何隔离级别下，都不会导致数据库理论意义上的丢失更新问题。这是因为，即使是`READ UNCOMMITTED`的事务隔离级别，对于行的DML操作，需要对行或其他粗粒度级别的对象加锁。因此在上述步骤2中，事务T2并不能对行记录`r`进行更新操作，其会被阻塞，直到事务T1提交。（**每个事务操作都是原子进行的**）

虽然数据库能阻止丢失更新问题的产生，但是在生产应用中还有另一个逻辑意义的丢失更新问题，而导致该问题的**并不是因为数据库本身的问题**。实际上，在所有多用户计算机系统环境下都有可能产生这个问题。简单地说来，出现下面的情况时，就会发生丢失更新：

1. 事务T1查询一行数据，放入本地内存，并显示给一个终端用户User1。
2. 事务T2也查询该行数据，并将取得的数据显示给终端用户User2。
3. User1修改这行记录，更新数据库并提交。
4. User2修改这行记录，更新数据库并提交。

显然，这个过程中用户User1的修改更新操作“丢失”了，而这可能会导致一个“恐怖”的结果。设想银行发生丢失更新现象，例如一个用户账号中有10 000元人民币，他用两个网上银行的客户端分别进行转账操作。第一次转账9000人民币，因为网络和数据的关系，这时需要等待。但是这时用户操作另一个网上银行客户端，转账1元，如果最终两笔操作都成功了，用户的账号余款是9999人民币，第一次转的9000人民币并没有得到更新，但是在转账的另一个账号却会收到这9000元，这导致的结果就是钱变多，而账不平。（**事务整体不是原子的**）

因此数据库只能保证事务中的每个操作的原子性，但是并不能保证事务整体的原子性，因此就出现了更新丢失的问题。要避免丢失更新发生，需要让事务在这种情况下的操作变成串行化，而不是并行的操作，解决办法就是通过加锁来实现。即在上述四个步骤的1中，对用户读取的记录加上一个排他X锁。同样，在步骤2的操作过程中，用户同样也需要加一个排他X锁。通过这种方式，步骤2就必须等待一步骤1和步骤3完成，最后完成步骤4。

下表所示的过程演示了如何避免这种逻辑上丢失更新问题的产生。

![丢失更新问题的处理方法](imgs/%E4%B8%A2%E5%A4%B1%E6%9B%B4%E6%96%B0%E9%97%AE%E9%A2%98%E7%9A%84%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95.png)

## 阻塞

因为不同锁之间的兼容性关系，在有些时刻一个事务中的锁需要等待另一个事务中的锁释放它所占用的资源，这就是**阻塞**。阻塞并不是一件坏事，其是为了确保事务可以并发且正常地运行。

在InnoDB存储引擎中，参数`innodb_lock_wait_timeout`用来控制等待的时间（默认是`50`秒），`innodb_rollback_on_timeout`用来设定是否在等待超时时对进行中的事务进行回滚操作（默认是`OFF`，代表不回滚）。参数`innodb_lock_wait_timeout`是动态的，可以在MySQL数据库运行时进行调整。

需要牢记的是，在默认情况下InnoDB存储引擎不会回滚超时引发的错误异常。其实InnoDB存储引擎在大部分情况下都不会对异常进行回滚，但是死锁异常会导致回滚。

### 阻塞超时演示

创建表，随便插入一些数据。

```sql
CREATE TABLE a (
  id int,
  PRIMARY KEY (id)
);

INSERT INTO a VALUES (1), (2), (4), (8);
```

创建两个会话分别开启事务A和事务B，并执行如下SQL语句。

```sql
-- 事务A
mysql> begin;
mysql> select * from a where id < 4 for update;

-- 事务B
mysql> begin;
mysql> insert into a values (9);
mysql> insert into a values (3);
ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction
mysql> commit;

-- 事务A
mysql> commit;
```

事务A中在Next-Key Lock算法下锁定了小于4的所有记录（其实也锁定了4这个记录本身）。在事务B中发现插入记录9是可以的，但是在插入记录3时，因为事务A中Next-Key Lock算法的关系，需要等待事务A释放这个资源，所以等待后产生了超时。并且此时事务B并没有提交或者回滚，只是插入记录3的操作失败。而这是十分危险的状态，因此用户必须判断是否需要`COMMIT`还是`ROLLBACK`，之后再进行下一步的操作。

如果事务B继续提交，事务A也跟着提交，这是查看数据库发现表a中记录9插入被提交了。

```sql
mysql> select * from a;
+----+
| id |
+----+
|  1 |
|  2 |
|  4 |
|  8 |
|  9 |
+----+
```

## 死锁

**死锁**是指两个或两个以上的事务在执行过程中，因争夺锁资源而造成的一种互相等待的现象。若无外力作用，事务都将无法推进下去。

### 等待事务回滚

解决死锁问题最简单的方式是不要有等待，将任何的等待都转化为回滚，并且事务重新开始。毫无疑问，这的确可以避免死锁问题的产生。然而在线上环境中，这可能导致并发性能的下降，甚至任何一个事务都不能进行。而这所带来的问题远比死锁问题更为严重，因为这很难被发现并且浪费资源。

### 超时机制

解决死锁问题最简单的一种方法是**超时**，即当两个事务互相等待时，当一个等待时间超过设置的某一阈值时，其中一个事务进行回滚，另一个等待的事务就能继续进行。在InnoDB存储引擎中，参数`innodb_lock_wait_timeout`用来设置超时的时间。

超时机制虽然简单，但是其仅通过超时后对事务进行回滚的方式来处理，或者说其是根据FIFO的顺序选择回滚对象（先超时先回滚）。但若超时的事务所占权重比较大，如事务操作更新了很多行，占用了较多的Undo Log，这时采用FIFO的方式，就显得不合适了，因为回滚这个事务的时间相对另一个事务所占用的时间可能会很多。

### 等待图

当前数据库还都普遍采用**wait-for graph（等待图）**的方式来进行死锁检测。较之超时的解决方案，这是一种更为主动的死锁检测方式。InnoDB存储引擎也采用的这种方式。wait-for graph要求数据库保存以下两种信息：

- 锁的信息链表
- 事务等待链表

通过上述链表可以构造出一张图，而在这个图中若存在回路，就代表存在死锁，因此资源间相互发生等待。在wait-for graph中，事务为图中的节点。而在图中，事务T1指向T2边的定义为：

- **事务T1等待事务T2所占用的资源**
- 事务T1最终等待T2所占用的资源，也就是事务之间在等待相同的资源，而**事务T1发生在事务T2的后面**

### 等待图示例

下面来看一个例子，当前事务和锁的状态如下图所示。

![示例事务状态和锁的信息](imgs/%E7%A4%BA%E4%BE%8B%E4%BA%8B%E5%8A%A1%E7%8A%B6%E6%80%81%E5%92%8C%E9%94%81%E7%9A%84%E4%BF%A1%E6%81%AF.png)

在Transaction Wait Lists中可以看到共有4个事务t1、t2、t3、t4，故在wait-for graph中应有4个节点。而事务t2对row1占用x锁，事务t1对row2占用s锁。事务t1需要等待事务t2中row1的资源，因此在wait-for graph中有条边从节点t1指向节点t2。事务t2需要等待事务t1、t4所占用的row2对象，故而存在节点t2到节点t1、t4的边。同样，存在节点t3到节点t1、t2、t4的边，因此最终的wait-for graph如图所示。

![wait-for graph](imgs/wait-for%20graph.png)

可以发现存在回路（t1，t2），因此存在死锁。通过上述的介绍，可以发现wait-for graph是一种较为主动的死锁检测机制，在每个事务请求锁并发生等待时都会判断是否存在回路，若存在则有死锁，通常来说InnoDB存储引擎选择**回滚undo量最小的事务**。

### 死锁的示例

如果程序是串行的，那么不可能发生死锁。死锁只存在于**并发**的情况，而数据库本身就是一个并发运行的程序，因此可能会发生死锁。

下表的操作演示了死锁的一种经典的情况，即A等待B，B在等待A，这种死锁问题被称为**AB-BA死锁**。

![死锁用例1](imgs/%E6%AD%BB%E9%94%81%E7%94%A8%E4%BE%8B1.png)

在上述操作中，会话B中的事务抛出了1213的错误提示，即表示事务发生了死锁。死锁的原因是会话A和B的资源在互相等待。**大多数的死锁InnoDB存储引擎本身可以侦测到，不需要人为进行干预**。但是在上面的例子中，在会话B中的事务抛出死锁异常后，会话A中马上得到了记录为2的这个资源，这其实是因为会话B中的事务发生了回滚，否则会话A中的事务是不可能得到该资源的。InnoDB存储引擎并不会回滚大部分的错误异常，但是死锁除外。**发现死锁后，InnoDB存储引擎会马上回滚一个事务**，这点是需要注意的。因此如果在应用程序中捕获了1213这个错误，其实并不需要对其进行回滚。

## 锁的升级

**锁升级（Lock Escalation）**是指将当前锁的粒度降低。举例来说，数据库可以把一个表的1000个行锁升级为一个页锁，或者将页锁升级为表锁。如果在数据库的设计中认为锁是一种稀有资源，而且想避免锁的开销，那数据库中会频繁出现锁升级现象。

Microsoft SQL Server数据库的设计认为锁是一种**稀有的资源**，在适合的时候会自动地将行、键或分页锁升级为更粗粒度的表级锁。这种升级保护了系统资源，防止系统使用太多的内存来维护锁，在一定程度上提高了效率。

InnoDB存储引擎**不存在锁升级的问题**。因为其不是根据每个记录来产生行锁的，相反，其根据每个事务访问的每个页对锁进行管理的，采用的是**位图**的方式。因此不管一个事务锁住页中一个记录还是多个记录，其开销通常都是一致的。

假设一张表有3 000 000个数据页，每个页大约有100条记录，那么总共有300 000 000条记录。若有一个事务执行全表更新的SQL语句，则需要对所有记录加X锁。若根据每行记录产生锁对象进行加锁，并且每个锁占用10字节，则仅对锁管理就需要差不多需要3GB的内存。而InnoDB存储引擎根据页进行加锁，并采用位图方式，假设每个页存储的锁信息占用30个字节，则锁对象仅需90MB的内存。由此可见两者对于锁资源开销的差距之大。
